{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "main.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LsywKe01dQpK"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import scipy.io\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_score\n",
        "from sklearn.metrics.cluster import adjusted_rand_score\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def dist(X, Y, p):\n",
        "  diff = np.abs(np.array(X) - np.array(Y))\n",
        "  p_pow = diff ** p\n",
        "  sum = np.sum(p_pow)\n",
        "  return sum ** (1/p)\n",
        "\n",
        "def get_dist_matrix(data, p):\n",
        "  n = data.shape[0]\n",
        "  dist_matrix = np.zeros((n, n))\n",
        "\n",
        "  for i in range(n):\n",
        "    for j in range(n):\n",
        "      dist_matrix[i][j] = dist(data.iloc[i], data.iloc[j], p)\n",
        "\n",
        "  return dist_matrix\n",
        "\n",
        "def approx_kmeans(dist_matrix, k):\n",
        "  Centers = np.array([])\n",
        "  n = dist_matrix.shape[0]\n",
        "  indexes = np.arange(n)\n",
        "  new_labels = np.zeros(n)\n",
        "\n",
        "  first = np.random.randint(n)\n",
        "  indexes = indexes[indexes != first]\n",
        "  cluster = 0\n",
        "  Centers = np.append(Centers, first)\n",
        "  new_labels[first] = cluster\n",
        "  cluster += 1\n",
        "\n",
        "  sum = 0\n",
        "  max_sum = 0\n",
        "  idx_max = 0\n",
        "  size = len(Centers)\n",
        "\n",
        "  while size < k:\n",
        "    for i in indexes:\n",
        "      for j in Centers:\n",
        "        sum += dist_matrix[i][int(j)]\n",
        "      if sum >= max_sum:\n",
        "        max_sum = sum\n",
        "        idx_max = i\n",
        "      sum = 0\n",
        "    indexes = indexes[indexes != idx_max]\n",
        "    Centers = np.append(Centers, idx_max)\n",
        "    new_labels[idx_max] = cluster\n",
        "    cluster += 1\n",
        "    max_sum = 0\n",
        "    size = len(Centers)\n",
        "\n",
        "\n",
        "  min_dist = np.inf\n",
        "\n",
        "  for i in indexes:\n",
        "    for j in Centers:\n",
        "      dist = dist_matrix[i][int(j)]\n",
        "      if dist <= min_dist:\n",
        "        min_dist = dist\n",
        "        new_labels[i] = new_labels[int(j)]\n",
        "    min_dist = np.inf\n",
        "\n",
        "  return Centers, new_labels, indexes\n",
        "\n",
        "def get_max_radius(Centers, indexes, new_labels, dist_matrix):\n",
        "  max_radius = 0\n",
        "  curr_max = 0\n",
        "\n",
        "  for i in Centers:\n",
        "    label = new_labels[int(i)]\n",
        "    for j in indexes:\n",
        "      if new_labels[j] == label:\n",
        "        dist = dist_matrix[j][int(i)]\n",
        "        if dist >= curr_max: curr_max = dist\n",
        "    if curr_max >= max_radius: max_radius = curr_max\n",
        "    curr_max = 0\n",
        "  \n",
        "  return max_radius"
      ],
      "metadata": {
        "id": "jgOOvF8t5TkI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataframes = []\n",
        "original_labels = []\n",
        "num_clusters = []\n",
        "distance_matrices = []"
      ],
      "metadata": {
        "id": "uFPd5temrAQs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"https://raw.githubusercontent.com/RdgFerreira/ALG2-TP2-Datasets/main/1.csv\")\n",
        "df.loc[df['Class'] == 'Kecimen', 'Class'] = 0\n",
        "df.loc[df['Class'] == 'Besni', 'Class'] = 1\n",
        "labels = np.array(df.loc[:, \"Class\"])\n",
        "df.drop('Class', axis=1, inplace=True)\n",
        "dataframes.append(df)\n",
        "original_labels.append(labels)\n",
        "num_clusters.append(2)\n",
        "distance_matrices.append(get_dist_matrix(df, 2))"
      ],
      "metadata": {
        "id": "y8M7G5FA25jV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"https://raw.githubusercontent.com/RdgFerreira/ALG2-TP2-Datasets/main/Absenteeism_at_work.csv\")\n",
        "cols = [0, 1, 2, 3, 4]\n",
        "df.drop(df.columns[cols], axis=1, inplace=True)\n",
        "cols = [5]\n",
        "df.drop(df.columns[cols], axis=1, inplace=True)\n",
        "cols = [4]\n",
        "df.drop(df.columns[cols], axis=1, inplace=True)\n",
        "labels = np.array(df.loc[:, 'Education'])\n",
        "df.drop('Education', axis=1, inplace=True)\n",
        "dataframes.append(df)\n",
        "original_labels.append(labels)\n",
        "num_clusters.append(4)\n",
        "distance_matrices.append(get_dist_matrix(df, 2))"
      ],
      "metadata": {
        "id": "G8j-eS0amYos"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('https://raw.githubusercontent.com/RdgFerreira/ALG2-TP2-Datasets/main/ObesityDataSet_raw_and_data_sinthetic.csv')\n",
        "cols = [5, 6, 7, 8, 10, 15]\n",
        "df.drop(df.columns[cols], axis=1, inplace=True)\n",
        "df.loc[df['NObeyesdad'] == 'Insufficient_Weight', 'NObeyesdad'] = 0\n",
        "df.loc[df['NObeyesdad'] == 'Normal_Weight', 'NObeyesdad'] = 1\n",
        "df.loc[df['NObeyesdad'] == 'Overweight_Level_I', 'NObeyesdad'] = 2\n",
        "df.loc[df['NObeyesdad'] == 'Overweight_Level_II', 'NObeyesdad'] = 3\n",
        "df.loc[df['NObeyesdad'] == 'Obesity_Type_I', 'NObeyesdad'] = 4\n",
        "df.loc[df['NObeyesdad'] == 'Obesity_Type_II', 'NObeyesdad'] = 5\n",
        "df.loc[df['NObeyesdad'] == 'Obesity_Type_III', 'NObeyesdad'] = 6\n",
        "df.loc[df['Gender'] == 'Male', 'Gender'] = 0\n",
        "df.loc[df['Gender'] == 'Female', 'Gender'] = 1\n",
        "df.loc[df['family_history_with_overweight'] == 'yes', 'family_history_with_overweight'] = 1\n",
        "df.loc[df['family_history_with_overweight'] == 'no', 'family_history_with_overweight'] = 0\n",
        "df.loc[df['SMOKE'] == 'yes', 'SMOKE'] = 1\n",
        "df.loc[df['SMOKE'] == 'no', 'SMOKE'] = 0\n",
        "df.loc[df['SCC'] == 'yes', 'SCC'] = 1\n",
        "df.loc[df['SCC'] == 'no', 'SCC'] = 0\n",
        "df.loc[df['CALC'] == 'no', 'CALC'] = 0\n",
        "df.loc[df['CALC'] == 'Sometimes', 'CALC'] = 1\n",
        "df.loc[df['CALC'] == 'Frequently', 'CALC'] = 2\n",
        "df.loc[df['CALC'] == 'Always', 'CALC'] = 3\n",
        "labels = np.array(df.loc[:, 'NObeyesdad'])\n",
        "df.drop('NObeyesdad', axis=1, inplace=True)\n",
        "dataframes.append(df)\n",
        "original_labels.append(labels)\n",
        "num_clusters.append(7)"
      ],
      "metadata": {
        "id": "-JAh9BKtvNck"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "distance_matrices.append(get_dist_matrix(df, 2))"
      ],
      "metadata": {
        "id": "7wuHS1lU02Td"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('https://raw.githubusercontent.com/RdgFerreira/ALG2-TP2-Datasets/main/heart_failure_clinical_records_dataset.csv')\n",
        "labels = np.array(df.loc[:, 'diabetes'])\n",
        "df.drop('diabetes', axis=1, inplace=True)\n",
        "dataframes.append(df)\n",
        "original_labels.append(labels)\n",
        "num_clusters.append(2)"
      ],
      "metadata": {
        "id": "wmC4F3TD8QKq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "distance_matrices.append(get_dist_matrix(df, 2))"
      ],
      "metadata": {
        "id": "sYF-6e1m-D74"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "radius = np.zeros((10, 30))\n",
        "silhouette_scores = np.zeros((10, 30))\n",
        "adjusted_rand_scores = np.zeros((10, 30))\n",
        "exec_times = np.zeros((10, 30))\n",
        "\n",
        "scikit_radius = np.zeros(10)\n",
        "scikit_silhouette_scores = np.zeros(10)\n",
        "scikit_adjusted_rand_scores = np.zeros(10)\n",
        "scikit_exec_times = np.zeros(10)"
      ],
      "metadata": {
        "id": "Zr9kDgTJh5SB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(dataframes)):\n",
        "  df = dataframes[i]\n",
        "  true_labels = original_labels[i]\n",
        "  dist_M = distance_matrices[i]\n",
        "\n",
        "  for j in range(30):\n",
        "    # 2-approx algorithm\n",
        "    start_time = time.time()\n",
        "    Centers, new_labels, indexes = approx_kmeans(dist_M, num_clusters[i])\n",
        "    exec_times[i][j] = time.time() - start_time\n",
        "    radius[i][j] = get_max_radius(Centers, indexes, new_labels, dist_M)\n",
        "    silhouette_scores[i][j] = silhouette_score(df, new_labels)\n",
        "    adjusted_rand_scores[i][j] = adjusted_rand_score(true_labels, new_labels)\n",
        "\n",
        "  # scikit approach\n",
        "  KM = KMeans(n_clusters = num_clusters[i], max_iter=30)\n",
        "  start_time = time.time()\n",
        "  KM.fit_predict(df)\n",
        "  scikit_exec_times[i] = time.time() - start_time\n",
        "  scikit_radius[i] = get_max_radius(Centers, indexes, KM.labels_, dist_M)\n",
        "  scikit_silhouette_scores[i] = silhouette_score(df, KM.labels_)\n",
        "  scikit_adjusted_rand_scores[i] = adjusted_rand_score(true_labels, KM.labels_)"
      ],
      "metadata": {
        "id": "GodsDnXZ5bIh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(dataframes)):\n",
        "  print(scikit_exec_times[i], np.mean(exec_times[i]))"
      ],
      "metadata": {
        "id": "oa8B80ANO_a8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(dataframes)):\n",
        "  print(scikit_radius[i], np.mean(radius[i]))"
      ],
      "metadata": {
        "id": "jaRc_-gpPkwu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(dataframes)):\n",
        "  print(scikit_silhouette_scores[i], np.mean(silhouette_scores[i]))"
      ],
      "metadata": {
        "id": "TOXn1EWvPwem"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(dataframes)):\n",
        "  print(scikit_adjusted_rand_scores[i], np.mean(adjusted_rand_scores[i]))"
      ],
      "metadata": {
        "id": "cT1wCKvghl3k"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}